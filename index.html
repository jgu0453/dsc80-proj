<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>League of Legends Esports Outcome Predictor</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>League of Legends Esports Outcome Predictor</h1>
    </header>

    <section id="introduction">
        <h2>Introduction</h2>
        <p>Competitive esports, particularly League of Legends (LoL), has become a global phenomenon, captivating millions of fans worldwide. In this project, we delve into the nuances of team performance and explore the factors that lead to victory in professional LoL matches. Using a rich dataset from Oracle's Elixir, we aim to answer a central question: How do key performance indicators (KPIs) such as gold difference at various timestamps influence win rates across different teams and regions?</p>
        <p>This dataset provides detailed match statistics from the 2022 LoL esports season, including information about teams, players, game outcomes, and numerous performance metrics. By analyzing these factors, we can uncover trends and insights that highlight what it takes to achieve competitive success in the esports arena. This question matters not just to fans seeking to understand their favorite teams better but also to analysts, players, and organizations aiming to gain a competitive edge.</p>
        <h3>Dataset Overview</h3>
        <p><strong>Total Rows:</strong> 150180</p>
        <p><strong>Relevant Columns:</strong></p>
        <ul>
            <li><strong>teamname:</strong> Name of the team.</li>
            <li><strong>result:</strong> Match outcome (win or loss).</li>
            <li><strong>goldat10, goldat15, goldat20:</strong> Total gold earned by the team at 10, 15, and 20 minutes.</li>
            <li><strong>golddiffat10, golddiffat15, golddiffat20:</strong> Gold difference between the team and its opponent at 10, 15, and 20 minutes.</li>
            <li><strong>kills, deaths, assists:</strong> Kill, death, and assist counts for the team.</li>
            <li><strong>towers, opp_towers:</strong> Number of towers destroyed by the team and their opponent.</li>
            <li><strong>dragons, opp_dragons:</strong> Number of dragons secured by the team and their opponent.</li>
        </ul>
        <p>These columns collectively offer insights into team strategies, early-game dominance, and how specific metrics correlate with the likelihood of winning a match.</p>
        <p>By examining this dataset, we aim to bring clarity to the role of key in-game metrics and identify the patterns that separate winning teams from the rest. Whether you're an esports enthusiast or a data analyst, this exploration promises to provide valuable insights into the dynamic world of competitive gaming.</p>
    </section>

    <section id="data-cleaning">
        <h2>Data Cleaning and Exploratory Data Analysis</h2>
        <p>We cleaned the dataset by replacing placeholders with NaN values, removing irrelevant columns (e.g., IDs), and creating new features such as "gold_per_minute." Below is the summary of the cleaned DataFrame:</p>
    
        <!-- Summary Image -->
        <div class="plot-container">
            <img src="data_cleaning.png" alt="Summary of the cleaned DataFrame">
        </div>

        <p>The following plots are results of different exploratory analysis on the dataset regarding useful metrics:</p>
        <!-- Container for the three images aligned in one row -->
        <div class="images-container">
            <div class="plot-container">
                <img src="game_length.png" alt="Distribution of Game Length">
                <p>The plot above shows the distribution of game length, with most matches lasting between 20 to 40 minutes.</p>
            </div>
            <div class="plot-container">
                <img src="Gold_per_min.png" alt="Distribution of Gold per Minute">
                <p>This plot highlights how well esports players generate gold per minute.</p>
            </div>
            <div class="plot-container">
                <img src="gold_diff.png" alt="Gold Difference at 15 Minutes by League">
                <p>This plot highlights how different leagues vary in their gold differences at 15 minutes, showcasing disparities in early-game strategies.</p>
            </div>
        </div>
    </section>

    <section id="missingness">
        <h2>Assessment of Missingness</h2>
        
        <!-- First Image: Missingness Overview -->
        <div class="plot-container">
            <h3>Missingness Overview</h3>
            <img src="missing.png" alt="Overview of Missingness">
        </div>
        
        <p>The column <strong>"gold_per_minute"</strong> in the dataset is suspected to be <strong>NMAR</strong> (Not Missing At Random). This is because missing values in this column may depend on the game’s completeness. Specifically, incomplete games or games with early terminations could lead to missing values in the <strong>"gold_per_minute"</strong> metric. For instance, if a match ends before reaching certain key timestamps, there may be insufficient data to calculate this feature, resulting in missing values.</p>
        
        <p>To investigate this further, we performed a missingness dependency test, analyzing whether the missingness of the <strong>"gold_per_minute"</strong> column depends on the game length. The test statistic and p-value help assess the relationship between the missingness of this column and the <strong>"gamelength"</strong> feature.</p>
    
        <div class="plot-container">
            <h3>Permutation Test for Missingness</h3>
            
            <p>The observed test statistic and the p-value indicate a significant relationship between missingness and game length. Specifically, a p-value of 0.0 suggests that the missingness of <strong>"gold_per_minute"</strong> is strongly dependent on the <strong>"gamelength"</strong> feature, reinforcing the hypothesis that the missing data may be NMAR.</p>
            
            <!-- Second Image: Permutation Test Plot -->
            <div id="permutation-test-plot">
                <img src="p_test.png" alt="Permutation Test Distribution">
            </div>
            
            <p>The plot above shows the empirical distribution of the test statistic from 1000 permutations of the data. The red dashed line represents the observed statistic, providing a visual interpretation of how extreme the observed value is in comparison to the permuted values.</p>
        </div>
    </section>
    
    <section id="hypothesis-test">
        <h2>Hypothesis Test: Team Performance Analysis</h2>
        
        <h3>Null and Alternative Hypotheses</h3>
        <p><strong>Null Hypothesis (H₀):</strong> There is no significant difference in the win rates between the different teams.</p>
        <p><strong>Alternative Hypothesis (H₁):</strong> There is a significant difference in the win rates between the different teams.</p>
        
        <h3>Test Statistic</h3>
        <p>To test these hypotheses, we performed a one-way ANOVA (Analysis of Variance) test, which compares the mean win rates across multiple teams. The test statistic is an F-statistic, which measures the variance between group means relative to the variance within the groups.</p>
    
        <h3>Test Results</h3>
        <p>The result of the ANOVA test is as follows:</p>
        <ul>
            <li><strong>F-statistic:</strong> 24.71</li>
            <li><strong>p-value:</strong> 0.0</li>
        </ul>
        <p>The p-value is extremely small (0.0), which suggests that there is strong evidence against the null hypothesis. Therefore, we reject the null hypothesis and conclude that there are significant differences in the win rates between the teams.</p>
        
        <h3>LPL vs. LDL Performance</h3>
        <p>We also compared the win rates of two specific leagues: LPL and LDL. The win rates for both leagues are:</p>
        <ul>
            <li><strong>LPL:</strong> 0.5</li>
            <li><strong>LDL:</strong> 0.5</li>
        </ul>
        <p>Interestingly, both leagues have the same win rate of 0.5, suggesting no significant difference in performance between the two leagues based on this metric.</p>
    
        <h3>Conclusion</h3>
        <p>Based on the ANOVA test, we reject the null hypothesis and conclude that there is a significant difference in win rates among the teams in the dataset. However, when comparing LPL and LDL, there is no observable difference in win rates, as both leagues have identical performance metrics.</p>
        
    </section>

    <section id="prediction-problem">
        <h2>Framing Prediction Problem</h2>
        <p>The problem we are addressing is a binary classification task. The goal is to predict whether a professional League of Legends team will win or lose a match based on various in-game performance metrics and events up to a certain point in the match. The response variable for this problem is <strong>result</strong>, where a win is labeled as 1 and a loss is labeled as 0. We chose this variable because it directly captures the outcome of the game and aligns with our goal of understanding the factors contributing to victory in competitive matches.</p>
        <p><strong>Evaluation Metric:</strong> To evaluate our model, we use accuracy as the primary performance metric. Accuracy was chosen because our dataset has a relatively balanced distribution of wins and losses, making it a suitable metric for measuring overall performance. However, if class imbalance were present, we would also consider metrics such as F1-score to account for both precision and recall. Accuracy provides a straightforward way to assess how well the model predicts the correct outcomes, which aligns with our objective of understanding win predictors.</p>
        <p><strong>Features and Time of Prediction:</strong> When selecting features for the model, we ensured that all the features used for prediction are available at the time of prediction during a match. Specifically, we used the following features:</p>
        <ul>
            <li><strong>Numerical Features:</strong>
                <ul>
                    <li><strong>goldat15:</strong> Total gold earned by the team at 15 minutes.</li>
                    <li><strong>gold_diff_per_minute:</strong> The gold difference per minute between the team and their opponent.</li>
                    <li><strong>KDA:</strong> Kill-death-assist ratio, a performance metric reflecting player effectiveness.</li>
                    <li><strong>gold_share:</strong> Proportion of the total gold earned by the team.</li>
                </ul>
            </li>
            <li><strong>Categorical Features:</strong>
                <ul>
                    <li><strong>pick1, pick2, pick3, pick4, pick5:</strong> Champions picked by the team during the draft phase.</li>
                    <li><strong>firstblood:</strong> Indicator of whether the team secured the first kill.</li>
                    <li><strong>firstdragon:</strong> Indicator of whether the team secured the first dragon.</li>
                    <li><strong>firstherald:</strong> Indicator of whether the team secured the first Rift Herald.</li>
                </ul>
            </li>
        </ul>
        <p>These features are carefully chosen to ensure they reflect in-game actions and states that occur before the match outcome is determined. For example, champion picks are decided during the draft phase, and early-game events such as securing the first blood or first dragon happen early in the match. These features allow the model to make predictions based on information that would be known at the time of prediction, maintaining the integrity and real-world applicability of our analysis.</p>
        <p>By carefully constructing the model and evaluation pipeline, we aim to provide actionable insights into the key factors that influence a team's success in professional League of Legends matches.</p>
    </section>

    <section id="baseline-model">
        <h2>Baseline Model</h2>
        
        <h3>Model Overview</h3>
        <p>The baseline predictive model aims to predict the match result based on several features. The model is built using logistic regression, a simple and interpretable classifier. The features included in the model are:</p>
        
        <ul>
            <li><strong>Quantitative:</strong> 1 feature - "goldat15" (gold earned at 15 minutes).</li>
            <li><strong>Nominal:</strong> 6 features - "pick1", "pick2", "pick3", "pick4", "pick5" (champion picks for the game), and binary outcomes for "firstblood", "firstdragon", and "firstherald" (whether the team secured the first blood, first dragon, or first herald).</li>
        </ul>
    
        <h3>Feature Preprocessing</h3>
        <p>We applied the following preprocessing steps to prepare the data for modeling:</p>
        <ul>
            <li>We dropped any rows with missing values in the selected feature columns.</li>
            <li>We encoded categorical features (e.g., champion picks and first objectives) using one-hot encoding to transform them into binary columns.</li>
            <li>The numerical feature ("goldat15") was standardized to have zero mean and unit variance using the StandardScaler.</li>
        </ul>
    
        <h3>Model Performance</h3>
        <p>The model was trained on the training set and evaluated on the test set. The performance of the model was assessed using accuracy and a classification report. The results are as follows:</p>
        <ul>
            <li><strong>Accuracy:</strong> 0.69</li>
            <li><strong>Classification Report:</strong></li>
        </ul>
        <pre>
            precision    recall  f1-score   support
    
               0       0.69      0.71      0.70      1699
               1       0.69      0.68      0.69      1673
    
        accuracy                           0.69      3372
        macro avg       0.69      0.69      0.69      3372
        weighted avg    0.69      0.69      0.69      3372
        </pre>
    
        <h3>Interpretation of Model Performance</h3>
        <p>The baseline model achieved an accuracy of 0.69, which indicates that it correctly predicts the match result 69% of the time. The classification report further reveals that the model performs equally well in predicting both classes (team winning or losing), with similar precision, recall, and f1-scores for both classes. Specifically, class 0 (team winning) has a precision of 0.69, recall of 0.71, and an f1-score of 0.70, while class 1 (team losing) has a precision of 0.69, recall of 0.68, and an f1-score of 0.69.</p>
    
        <h3>Is the Model Good?</h3>
        <p>Given the accuracy and balanced performance across both classes, the baseline model provides a reasonable performance. While the accuracy is fairly good, there is still room for improvement. The model's performance could benefit from exploring more advanced algorithms, adding additional features, or tuning the hyperparameters to increase the accuracy further.</p>
    
        <h3>Conclusion</h3>
        <p>While the baseline logistic regression model offers a solid starting point, it can be enhanced with more features and other machine learning techniques to improve its prediction accuracy and robustness.</p>
    
    </section>

    <section id="final-model">
        <h2>Final Model</h2>
        
        <h3>Additional Features</h3>
        <p>In the final model, several new features were added to improve the prediction of match outcomes. These features were selected based on their relevance to the data generating process and the potential insights they provide into team performance:</p>
        <ul>
            <li><strong>gold_diff_per_minute:</strong> The difference in gold earned per minute between the two teams, adjusted for game length. This feature highlights the relative economic advantage of a team during the match, which can be critical in predicting the winner.</li>
            <li><strong>KDA (Kills, Deaths, Assists ratio):</strong> This metric reflects a player's overall performance in terms of kills, deaths, and assists, which are directly linked to a team’s success in fights and objectives. It provides insight into the efficiency and impact of the team's individual players.</li>
            <li><strong>gold_share:</strong> The proportion of the team's gold relative to the total gold on the map. A higher gold share can indicate a more impactful team composition, often correlating with better performance.</li>
        </ul>
        <p>These features were selected because they offer deeper insights into the team's economic and individual performance during the match, which are crucial for predicting the match outcome. By considering these metrics, the model gains a better understanding of the relative strength of the teams, helping to make more accurate predictions.</p>
    
        <h3>Modeling Algorithm</h3>
        <p>For the final model, we chose the <strong>Random Forest Classifier</strong>, a robust ensemble learning method that is well-suited for handling complex, high-dimensional datasets. The Random Forest algorithm aggregates predictions from multiple decision trees, reducing overfitting and improving generalization.</p>
        
        <h3>Hyperparameter Tuning</h3>
        <p>We used <strong>GridSearchCV</strong> to optimize the hyperparameters of the Random Forest model. The grid search was performed over the following parameters:</p>
        <ul>
            <li><strong>n_estimators:</strong> Number of trees in the forest (100, 200).</li>
            <li><strong>max_depth:</strong> Maximum depth of the trees (None, 10, 20).</li>
            <li><strong>min_samples_split:</strong> Minimum number of samples required to split an internal node (2, 5, 10).</li>
        </ul>
        <p>The best hyperparameters identified through grid search were:</p>
        <pre>Best Hyperparameters: {'classifier__max_depth': None, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200}</pre>
    
        <h3>Final Model Performance</h3>
        <p>After training the final model with the optimal hyperparameters, we evaluated its performance on the test set. The results show a significant improvement in both accuracy and overall classification performance compared to the baseline model:</p>
        <ul>
            <li><strong>Accuracy:</strong> The final model achieved an impressive accuracy of <strong>0.97</strong>, significantly higher than the baseline model’s accuracy of 0.69.</li>
            <li><strong>Classification Report:</strong></li>
        </ul>
        <pre>
            precision    recall  f1-score   support
    
               0       0.97      0.96      0.97      1699
               1       0.96      0.97      0.97      1673
    
        accuracy                           0.97      3372
        macro avg       0.97      0.97      0.97      3372
        weighted avg    0.97      0.97      0.97      3372
        </pre>
    
        <h3>Interpretation of Model Performance</h3>
        <p>The final model’s accuracy of 0.97 represents a significant improvement over the baseline model’s 0.69. Both precision and recall are exceptionally high for both classes, with the f1-scores exceeding 0.97. This indicates that the model is highly accurate and reliable in predicting the outcome of the matches. The balanced performance across both classes (team winning and losing) suggests that the model is robust and not biased toward any particular outcome.</p>
    
        <h3>Conclusion</h3>
        <p>By adding new features such as gold difference, KDA, and gold share, and using a Random Forest Classifier with tuned hyperparameters, the final model has achieved exceptional performance. The model’s accuracy has increased substantially, providing a much stronger prediction of match outcomes compared to the baseline model. The high precision and recall values further confirm the model’s reliability and effectiveness. With these improvements, the final model offers a solid and practical solution for predicting the outcome of future matches.</p>
    
    </section>

    <section id="fairness-analysis">
        <h2>Fairness Analysis</h2>
    
        <h3>Choice of Groups</h3>
        <p>In this fairness analysis, we focus on the <strong>"side"</strong> column as the sensitive attribute. The two groups are:</p>
        <ul>
            <li><strong>Group X:</strong> The "Red" side</li>
            <li><strong>Group Y:</strong> The "Blue" side</li>
        </ul>
        <p>We aim to evaluate whether the model's performance differs between these two groups to assess fairness. A model is considered fair if its performance (e.g., accuracy) is similar across different groups, without favoring one over the other.</p>
    
        <h3>Evaluation Metric</h3>
        <p>The evaluation metric used for this fairness analysis is <strong>accuracy</strong>, which measures the percentage of correct predictions for each group. We calculate the accuracy for both the Red and Blue sides to determine if there is any performance disparity between them.</p>
    
        <h3>Hypotheses</h3>
        <p>We will test whether the model performs equally well on both sides:</p>
        <ul>
            <li><strong>Null Hypothesis (H₀):</strong> There is no significant difference in accuracy between the Red and Blue sides (i.e., the model's performance is independent of the "side" attribute).</li>
            <li><strong>Alternative Hypothesis (H₁):</strong> There is a significant difference in accuracy between the Red and Blue sides (i.e., the model's performance depends on the "side" attribute).</li>
        </ul>
    
        <h3>Test Statistic and Significance Level</h3>
        <p>The test statistic used will be the difference in accuracy between the Red and Blue sides. We will use a <strong>two-sample t-test</strong> to compare the accuracy scores of the two groups. The significance level (α) is set to 0.05.</p>
    
        <h3>Results</h3>
        <p>The performance of the model by side was as follows:</p>
        <pre>
        Accuracy by Side:
        Side Blue: 0.9668
        Side Red: 0.9662
        </pre>
    
        <h3>Confusion Matrix and Classification Report by Side</h3>
        <p>We also analyzed the confusion matrix and classification report for each side. This breakdown helps us better understand how the model performs for each group in terms of precision, recall, and f1-score.</p>
    
        <pre>
        Confusion Matrix for Side Blue:
        [[781  33]
         [ 23 849]]
        
        Classification Report for Side Blue:
                    precision    recall  f1-score   support
    
               0       0.97      0.96      0.97       814
               1       0.96      0.97      0.97       872
    
        accuracy                           0.97      1686
       macro avg       0.97      0.97      0.97      1686
    weighted avg       0.97      0.97      0.97      1686
    
        Confusion Matrix for Side Red:
        [[858  27]
         [ 30 771]]
        
        Classification Report for Side Red:
                    precision    recall  f1-score   support
    
               0       0.97      0.97      0.97       885
               1       0.97      0.96      0.97       796
    
        accuracy                           0.97      1686
       macro avg       0.97      0.97      0.97      1686
    weighted avg       0.97      0.97      0.97      1686
        </pre>
    
        <h3>Conclusion</h3>
        <p>Based on the accuracy scores and the classification reports, the model performs very similarly on both the Red and Blue sides, with only a very slight difference in accuracy (0.9668 for Blue vs. 0.9662 for Red). Both groups have high accuracy, precision, recall, and f1-scores, showing that the model is performing well across both sides.</p>
        <p>Thus, we fail to reject the null hypothesis (H₀) and conclude that the model's performance does not significantly depend on the "side" attribute. This indicates that the model is fairly balanced and performs similarly across both the Red and Blue sides. There is no significant disparity in model performance between the two groups, suggesting the model is fair with respect to the sensitive attribute "side".</p>
    
    </section>

</body>
<footer>
    <p>&copy; 2024 Jonathan Gu. All Rights Reserved.</p>
    <p>
        <a href="#privacy-policy">Privacy Policy</a> | 
        <a href="#terms-of-service">Terms of Service</a>
    </p>
</footer>
</html>
